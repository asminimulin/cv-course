{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asminimulin/cv-course/blob/main/02-image-linear-classification/Linear_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRBhMZtdf94"
      },
      "source": [
        "# Download dataset with Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNE5Qqw_rdsV"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKAZ-aQtrg8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524ef476-97e6-46a7-8fa2-269f6427bc30"
      },
      "source": [
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Define transformation for each image\n",
        "transform  = transforms.Compose([\n",
        "    # transforms.Grayscale(1),\n",
        "    # transforms.to\n",
        "    transforms.Lambda(lambda x: np.array(x).flatten()) #Stretch image into row [32,32,3] -> [3072]\n",
        "])\n",
        "\n",
        "# Download a CIFAR10 dataset\n",
        "dataset = datasets.CIFAR10(\"/content\",\n",
        "                           train=True,\n",
        "                           transform = transform,\n",
        "                           download=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3F4IoDErlcw"
      },
      "source": [
        "## Split dataset & define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu02DmABYxoh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e49f2b3d-f2bb-4a49-ece7-8d0ec4aa4e3f"
      },
      "source": [
        "train_ds, val_ds, _= random_split(dataset, [20000,1000 ,29000])\n",
        "# Hint: Perform debug on smaller subset\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size = batch_size)\n",
        "val_loader = DataLoader(val_ds, batch_size = batch_size)\n",
        "\n",
        "# Display one image\n",
        "for images, class_nums in train_loader:\n",
        "  print (images.shape,class_nums.shape) # class_nums are tensor!\n",
        "  display(Image.fromarray(images[0].reshape((32,32,3)).numpy()),class_nums[0].item()) \n",
        "  break \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3072]) torch.Size([256])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FAFD7ABB710>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqC6xXhSeUPr"
      },
      "source": [
        "# Implement LinearClassifier class for CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaxIJUM7eQUp"
      },
      "source": [
        "class LinearClassifier:\n",
        "  def __init__(self, labels, ):\n",
        "    self.labels = labels\n",
        "    self.classes_num = len(labels)\n",
        "    # Generate a random weight matrix of small numbers\n",
        "    # You can change this code\n",
        "    self.W = np.random.randn(3072, self.classes_num) * 0.0001 \n",
        "    self.batch_size = 200\n",
        "\n",
        "  \n",
        "  def train(self, x_batch, y_batch, learning_rate = 1e-8):\n",
        "    \"\"\"\n",
        "      Arguments:\n",
        "        x  (numpy.array): collection of objects (batch)\n",
        "        y  (numpy.array): collection of integer \n",
        "        representing a class number for objects from x\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    loss_val, grad = self.loss(x_batch, y_batch)\n",
        "\n",
        "    # Update weights (self.W)\n",
        "\n",
        "    return loss/x_batch.shape[0]\n",
        "\n",
        "  def loss(self,x, y): # x and y are batches\n",
        "    \"\"\"\n",
        "      Arguments:\n",
        "        x  (numpy.array): collection of objects (batch)\n",
        "        y  (numpy.array): collection of integer \n",
        "        representing a class number for objects from x\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    loss = 0.0\n",
        "    dW = np.zeros(self.W.shape)\n",
        "\n",
        "    # Calculate Multiclass SVM or Cross-entropy loss over a batch \n",
        "\n",
        "    # Calculate gradients (dL/dW) and store it in dW\n",
        "\n",
        "    return loss, dW\n",
        "      \n",
        "  def predict(self,x):\n",
        "    x = self.add_ones(x)\n",
        "    scores = x.dot(self.W) # (256, 3073) * (3073, 10)\n",
        "    return np.argmax(scores,axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyVPgrr5xjhU"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5zVN1kHd43W"
      },
      "source": [
        "## Function for accuracy checking\n",
        "\n",
        "Don't change this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzhRClCsdzJw"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def validate(model,dataloader):\n",
        "  y_predicted = np.array([])\n",
        "  y_gtrue = np.array([])\n",
        "  for images, class_nums in dataloader:\n",
        "    index = model.predict(images.numpy())\n",
        "    y_predicted = np.append(y_predicted,index) \n",
        "    y_gtrue = np.append(y_gtrue,class_nums.numpy()) \n",
        "  return accuracy_score(y_gtrue, y_predicted)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQr1qYUlxq7X"
      },
      "source": [
        "## Train loop\n",
        "Let's train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phcDEj7OdpGS"
      },
      "source": [
        "\n",
        "model = LinearClassifier(dataset.classes)\n",
        "best_accuracy = 0\n",
        "for epoch in range(25):\n",
        "  for images, class_nums in train_loader:\n",
        "    loss = model.train(images.numpy(), class_nums.numpy())\n",
        "    accuracy = validate(model,val_loader)\n",
        "  if best_accuracy < accuracy:\n",
        "     best_accuracy = accuracy\n",
        "  print(f\"Epoch {epoch} Loss: {loss}, Accuracy:{accuracy}\")\n",
        "\n",
        "print(f\"Best accuracy is {best_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4tIFR5bwZFi"
      },
      "source": [
        "# Check model on test dataset\n",
        "\n",
        "You must get accuracy above 0.35\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM0pWYJlwibm"
      },
      "source": [
        "test_dataset = datasets.CIFAR10(\"content\",\n",
        "                           train=False,\n",
        "                           transform = transform, # Transforms stay the same\n",
        "                           download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
        "\n",
        "accuracy = validate(model,test_loader)\n",
        "print(f\"Accuracy on test:{accuracy}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsImxpggG8bH"
      },
      "source": [
        "# Place for brief conclusion\n",
        "Feel free to describe troubles here.\n",
        "\n",
        "\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ13OmfCEb1w"
      },
      "source": [
        "# Ideas for extra work\n",
        "\n",
        "- Implenment CrossEntropyLoss function\n",
        "- Implement bias trick\n",
        "- Add regularization to SVM loss\n",
        "- Find best learning rate and regularization strength using Cross-Validation\n",
        "- Normalize data\n",
        "\n",
        "\n",
        " "
      ]
    }
  ]
}